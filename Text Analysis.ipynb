{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPhfqmMAyxpU3HITnvPT8h/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mRcfsCzbrRxu","executionInfo":{"status":"ok","timestamp":1699548200688,"user_tz":-330,"elapsed":65365,"user":{"displayName":"Sapan Patel","userId":"06816076756338137771"}},"outputId":"f8c8ce22-f46b-493a-9420-a429ed65e19a"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install syllables"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qw5L4ELAoBad","executionInfo":{"status":"ok","timestamp":1699534357100,"user_tz":-330,"elapsed":7291,"user":{"displayName":"Sapan Patel","userId":"06816076756338137771"}},"outputId":"3c043495-8eab-4fe9-e139-24301711b3cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: syllables in /usr/local/lib/python3.10/dist-packages (1.0.9)\n","Requirement already satisfied: cmudict<2.0.0,>=1.0.11 in /usr/local/lib/python3.10/dist-packages (from syllables) (1.0.15)\n","Requirement already satisfied: importlib-metadata<7.0,>=5.1 in /usr/local/lib/python3.10/dist-packages (from syllables) (6.8.0)\n","Requirement already satisfied: importlib-resources<6.0.0,>=5.10.1 in /usr/local/lib/python3.10/dist-packages (from cmudict<2.0.0,>=1.0.11->syllables) (5.13.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=5.1->syllables) (3.17.0)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kU934OiQgORO","executionInfo":{"status":"ok","timestamp":1699538412981,"user_tz":-330,"elapsed":690,"user":{"displayName":"Sapan Patel","userId":"06816076756338137771"}},"outputId":"c04972f7-48c6-46a0-fd10-818cca198ac6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Text data extracted from https://insights.blackcoffer.com/continued-demand-for-sustainability/ and saved to 123.txt\n"]}],"source":["from textblob.compat import request\n","import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","\n","\n","def extract_text_from_url(url):\n","    # Send a GET request to the URL\n","    response = requests.get(url)\n","\n","    # Check if the request was successful (status code 200)\n","    if response.status_code == 200:\n","        # Parse the HTML content using BeautifulSoup\n","        soup = BeautifulSoup(response.text, 'html.parser')\n","\n","        # Extract text from the parsed HTML\n","        text = soup.get_text()\n","\n","        return text\n","    else:\n","        # If the request was not successful, print an error message\n","        print(f\"Error: Unable to fetch content from {url}\")\n","        return None\n","\n","def save_text_to_file(text, filename):\n","    # Save the extracted text to a text file\n","    with open(filename, 'w', encoding='utf-8') as file:\n","        file.write(text)\n","\n","# Example usage:\n","\n","url = 'https://insights.blackcoffer.com/continued-demand-for-sustainability/'\n","text_data = extract_text_from_url(url)\n","\n","\n","if text_data:\n","    save_text_to_file(text_data, '123.txt')\n","    print(f\"Text data extracted from {url} and saved to 123.txt\")\n","\n","\n"]},{"cell_type":"code","source":["from textblob import TextBlob\n","import re\n","import syllables\n","import pandas as pd\n","\n","def analyze_text(text):\n","    # Create a TextBlob object\n","    blob = TextBlob(text)\n","\n","    # Sentiment Analysis\n","    polarity_score = blob.sentiment.polarity\n","    subjectivity_score = blob.sentiment.subjectivity\n","\n","    # Tokenize the text into sentences\n","    sentences = re.split(r'[.!?]', text)\n","    sentences = [sentence for sentence in sentences if sentence]\n","\n","    # Calculate average sentence length\n","    avg_sentence_length = sum(len(sentence.split()) for sentence in sentences) / len(sentences)\n","\n","    # Calculate percentage of complex words\n","    words = re.findall(r'\\b\\w+\\b', text)\n","    complex_word_count = sum(len(word) > 2 and syllables.estimate(word) > 2 for word in words)\n","    percentage_complex_words = (complex_word_count / len(words)) * 100\n","\n","    # Calculate FOG index\n","    fog_index = 0.4 * (avg_sentence_length + percentage_complex_words)\n","\n","    # Calculate average number of words per sentence\n","    avg_words_per_sentence = len(words) / len(sentences)\n","\n","    # Calculate average word length\n","    avg_word_length = sum(len(word) for word in words) / len(words)\n","\n","\n","\n","    # Count personal pronouns (this is just a simple example)\n","    personal_pronouns = sum(word.lower() in ['i', 'me', 'my', 'mine', 'we', 'us', 'our', 'ours'] for word in words)\n","\n","    # Calculate syllables per word\n","    syllables_per_word = sum(syllables.estimate(word) for word in words) / len(words)\n","\n","    Positive_score = max(polarity_score, 0)\n","    Negative_score = -min(polarity_score, 0)\n","    Polarity_score = polarity_score\n","    Subjectivity_score = subjectivity_score\n","    Avg_sentence_length = avg_sentence_length\n","    Percentage_complex_words = percentage_complex_words\n","    Fog_index = fog_index\n","    Avg_words_per_sentence = avg_words_per_sentence\n","    Complex_word_count = complex_word_count\n","    Word_count = len(words)\n","    Syllables_per_word = syllables_per_word\n","    Personal_pronouns = personal_pronouns\n","    Avg_word_length = avg_word_length\n","\n","    # Display the results\n","    print(\"POSITIVE SCORE:\", Positive_score)\n","    print(\"NEGATIVE SCORE:\", Negative_score)\n","    print(\"POLARITY SCORE:\", Polarity_score)\n","    print(\"SUBJECTIVITY SCORE:\", Subjectivity_score)\n","    print(\"AVG SENTENCE LENGTH:\", Avg_sentence_length)\n","    print(\"PERCENTAGE OF COMPLEX WORDS:\", Percentage_complex_words)\n","    print(\"FOG INDEX:\", Fog_index)\n","    print(\"AVG NUMBER OF WORDS PER SENTENCE:\", Avg_words_per_sentence)\n","    print(\"COMPLEX WORD COUNT:\", Complex_word_count)\n","    print(\"WORD COUNT:\", Word_count)\n","    print(\"SYLLABLES PER WORD:\", Syllables_per_word)\n","    print(\"PERSONAL PRONOUNS:\", Personal_pronouns)\n","    print(\"AVG WORD LENGTH:\", Avg_word_length)\n","\n","# Save the Analyzed Data into Excel file :\n","    data = {\n","    'URL_ID': [52768.2],\n","    'URL':[url],\n","    'POSITIVE SCORE': [Positive_score],\n","    'NEGATIVE SCORE': [Negative_score],\n","    'POLARITY SCORE': [Polarity_score],\n","    'SUBJECTIVITY SCORE': [Subjectivity_score],\n","    'AVG SENTENCE LENGTH': [Avg_sentence_length],\n","    'PERCENTAGE OF COMPLEX WORDS': [Percentage_complex_words],\n","    'FOG INDEX': [Fog_index],\n","    'AVG NUMBER OF WORDS PER SENTENCE': [Avg_words_per_sentence],\n","    'COMPLEX WORD COUNT': [Complex_word_count],\n","    'WORD COUNT': [Word_count],\n","    'SYLLABLES PER WORD': [Syllables_per_word],\n","    'PERSONAL PRONOUNS': [Personal_pronouns],\n","    'AVG WORD LENGTH': [Avg_word_length],\n","     }\n","\n","     # Create a DataFrame from the dictionary\n","    df = pd.DataFrame(data)\n","\n","    # Save the DataFrame to an Excel file\n","    excel_file_path = '/content/drive/MyDrive/Output Data Structure.xlsx'\n","    try:\n","       existing_df = pd.read_excel(excel_file_path)\n","    except FileNotFoundError:\n","       existing_df = pd.DataFrame()\n","\n","    # Create a DataFrame from the new data\n","    new_df = pd.DataFrame(data)\n","\n","    # Concatenate the existing DataFrame with the new data\n","    result_df = pd.concat([existing_df, new_df], ignore_index=True)\n","\n","    # Save the combined DataFrame to the Excel file\n","    result_df.to_excel(excel_file_path, index=False)\n","    print(f\"Data saved to {excel_file_path}\")\n","\n","# Analyze The Text from the Text file :\n","with open('123.txt', 'r', encoding='utf-8') as file:\n","    text_data = file.read()\n","\n","analyze_text(text_data)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L7b108eii947","executionInfo":{"status":"ok","timestamp":1699538416479,"user_tz":-330,"elapsed":974,"user":{"displayName":"Sapan Patel","userId":"06816076756338137771"}},"outputId":"4fb43a29-72f7-4667-f923-b225da7b9a89"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["POSITIVE SCORE: 0.09786173951496534\n","NEGATIVE SCORE: 0\n","POLARITY SCORE: 0.09786173951496534\n","SUBJECTIVITY SCORE: 0.40700926313829544\n","AVG SENTENCE LENGTH: 32.24590163934426\n","PERCENTAGE OF COMPLEX WORDS: 31.237218813905933\n","FOG INDEX: 25.39324818130008\n","AVG NUMBER OF WORDS PER SENTENCE: 32.0655737704918\n","COMPLEX WORD COUNT: 611\n","WORD COUNT: 1956\n","SYLLABLES PER WORD: 2.1109406952965237\n","PERSONAL PRONOUNS: 33\n","AVG WORD LENGTH: 5.899284253578732\n","Data saved to /content/drive/MyDrive/Output Data Structure.xlsx\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"LaGBAXYEGeYv"},"execution_count":null,"outputs":[]}]}